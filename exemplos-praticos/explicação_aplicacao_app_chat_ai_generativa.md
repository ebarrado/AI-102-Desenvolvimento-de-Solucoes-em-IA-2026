# Passo a Passo - Aplicativo de bate-papo com IA generativa

![alt text](/imagens/app_chat_ia_generativa.png)

Antes de come√ßar a programar acesse o arquivo [configura√ß√£o de ambiente](configuracao_ambiente.md).

## Configura√ß√£o Arquivo `app.py`

```python
import streamlit as st
import os
from dotenv import load_dotenv
from openai import AzureOpenAI
```
* `import streamlit as st`: Importa o Streamlit, framework usado para criar aplica√ß√µes web em Python.
O as st cria um apelido para facilitar o uso.

* `import os`: Permite acessar vari√°veis do sistema operacional (ex: vari√°veis de ambiente).
* `from dotenv import load_dotenv`: Importa a fun√ß√£o que carrega vari√°veis do arquivo .env.

* `from openai import AzureOpenAI`:Importa a classe que permite conectar ao Azure OpenAI.

## Carregando as Vari√°veis

Carrega as vari√°veis do arquivo `.env`para dentro do sistema

```python
load_python
```
O arquivo `.env`est√° configurado da seguinte forma:

```bash
AZURE_OPENAI_ENDPOINT=https://...
AZURE_OPENAI_KEY=xxxxx
MODEL_DEPLOYMENT=modelo-chat-barrado
```
## Configura√ß√£o do Ambiente

```python
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY")
MODEL_DEPLOYMENT = os.getenv("MODEL_DEPLOYMENT", "modelo-chat-barrado")
API_VERSION = "2024-12-01-preview"
```

* `os.getenv()`: pega valores do .env

* Se `MODEL_DEPLOYMENT`:  n√£o existir, usa "modelo-chat-barrado" como padr√£o.

* Define a vers√£o da API que ser√° usada.

## Fun√ß√£o que inicia o Cliente Azure OpenAI

```Python
@st.cache_resource
def get_openai_client():
```
* `@st.cache_resource`:
Diz ao Streamlit para criar o cliente apenas uma vez e reutilizar depois.
Isso melhora desempenho.

```python
if not AZURE_OPENAI_KEY:
    st.error("Chave de API n√£o encontrada")
    return None
```

* ‚úî Verifica se a chave existe
* ‚úî Se n√£o existir, mostra erro

```python
cliente = AzureOpenAI(
    azure_endpoint= AZURE_OPENAI_ENDPOINT,
    api_key= AZURE_OPENAI_KEY,
    api_version= API_VERSION
)
```
* ‚úî Cria o objeto cliente
* ‚úî Conecta com o Azure OpenAI

## Configura√ß√£o da P√°gina

```python
st.set_page_config(
    page_title="Chat IA Generativa - Azure AI Foundry",
    page_icon="ü§ñ",
    layout="wide"    
)
```
* T√≠tulo da aba do navegador
* √çcone
* Layout em tela larga

## Inicializa√ß√£o da Mem√≥ria da Conversa

```python
if "messages" not in st.session_state:
```

### `session_state`

√â a mem√≥ria da aplica√ß√£o durante a sess√£o do usu√°rio.

```python
st.session_state.messages = [
    {
        "role": "system", 
        "content": "Voc√™ √© um professor..."
    }
]
```
* ‚úî Define o comportamento do assistente
* ‚úî Essa mensagem do tipo "system" orienta o modelo

## Sidebar (Painel Lateral)

```python
with st.sidebar:
```
* Cria o painel lateral.

## Controle de Temperatura

```python
temperatura = st.slider(...)
```
Controla criatividade:

* 0.0 ‚Üí respostas mais objetivas
* 1.0 ‚Üí mais criativas

## Controle de Max Tokens

Define tamanho m√°ximo da resposta.

```python
max_tokens = st.slider(...)
```

## Controle Top-P

```python
top_p = st.slider(...)
```
Controla diversidade das palavras usadas.

## Bot√£o Limpar Conversa

```python
if st.button("üö®Limpar Conversa"):
```
* ‚úî Testa se o cliente foi criado
* ‚úî Mostra status da conex√£o

# Exibi√ß√£o das Mensagens

```python
for message in st.session_state.messages:
```
Percorre todas as mensagens salvas.

```python
Percorre todas as mensagens salvas.
```

Renderiza:

* Mensagem do usu√°rio
* Mensagem do assistente

## Entrada do Usu√°rio

```python
if prompt := st.chat_input("üí¨ Digite sua mensagem..."):
```

```text
:= √© o operador WALRUS
Ele atribui e verifica ao mesmo tempo.
```

## Enviando para API

```python
response = client.chat.completions.create(
```
Par√¢metros importantes:

* model
* messages
* temperature
* max_tokens
* top_p
* stream=True:  ativa streaming

## Streaming da Resposta

```python
for chunk in response:
```
O modelo envia a resposta em partes.

```python
full_response += content
message_placeholder.markdown(full_response + "‚ñå")
```
* ‚úî Junta os peda√ßos
* ‚úî Mostra digitando em tempo real

## Tratamento de Erros

```python
except Exception as e:
```
Trata erros comuns:

* 401 ‚Üí erro de autentica√ß√£o

* 404 ‚Üí modelo n√£o encontrado

* 429 ‚Üí limite excedido

Connection ‚Üí erro de conex√£o

Isso melhora a experi√™ncia do usu√°rio.

# Rodap√©

```python
col1, col2, col3 = st.columns(3)
```
Divide a tela em 3 colunas.

Exibe:

* Tipo de autentica√ß√£o
* Nome do modelo
* Limite de tokens

## C√≥digo Final

```python
import streamlit as st
import os
from dotenv import load_dotenv
from openai import AzureOpenAI

load_dotenv()

#Configura√ß√£o do Ambiente
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY")
MODEL_DEPLOYMENT = os.getenv("MODEL_DEPLOYMENT", "modelo-chat-barrado")
API_VERSION = "2024-12-01-preview"


#INICIAR O CLIENTE DO OPENAI
@st.cache_resource
def get_openai_client():
    """
    Cria e retorna um cliente Azure OpenAI
    """
    try:
        if not AZURE_OPENAI_KEY:
            st.error("Chave de API n√£o encontrada")
            return None
        cliente = AzureOpenAI(
            azure_endpoint= AZURE_OPENAI_ENDPOINT,
            api_key= AZURE_OPENAI_KEY,
            api_version= API_VERSION
        )
        return cliente
    except Exception as e:
        st.error(f"Erro na autentica√ß√£o: {str(e)}")
        
st.set_page_config(
    page_title="Chat IA Generativa - Azure AI Foundry",
    page_icon="ü§ñ",
    layout="wide"    
)

st.title("ü§ñ Chat IA Generativa - Azure AI Foundry")
st.caption(f"{MODEL_DEPLOYMENT} via Azure OpenAI")

if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system", "content":
                "Voc√™ √© um professor de tecnologia, especializado em treinamentos Microsoft para certifica√ß√µes de n√≠vel fundamentos, associado e especialista. "
                "Explique de forma clara, objetiva e did√°tica. "
                "Use linguagem simples e exemplos pr√°ticos. "
                "Responda em Portugu√™s do Brasil. "
        }
    ]

with st.sidebar:
    st.header("Configura√ß√µes")
    
    #Controles
    temperatura = st.slider(
        "Temperatura",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="Controla a criatividade das respostas"
    )
    max_tokens = st.slider(
        "M√°ximo de tokens",
        min_value=100,
        max_value=4000,
        value=1000,
        step=100,
        help="Tamanho m√°ximo da resposta"
    )
    
    top_p = st.slider(
        "Top P",
        min_value=0.1,
        max_value=1.0,
        value=0.95,
        step=0.05
    )
    if st.button("üö®Limpar Conversa", use_container_width=True):
        st.session_state.messages = [
            {"role":"system","content":"Voc√™ √© um assistente √∫til e responde em portugu√™s do Brasil"}
        ]   
        st.rerun()
    # Informa√ß√µes do sistema
    st.header("‚ÑπÔ∏è Informa√ß√µes da Implanta√ß√£o")
    
    # Verifica status da conex√£o
    client = get_openai_client()
    status = "‚úÖ Conectado" if client else "‚ùå Desconectado"
    
    st.info(f"""
    **Modelo:** {MODEL_DEPLOYMENT}
    **Endpoint:** {AZURE_OPENAI_ENDPOINT.split('//')[1].split('.')[0] if AZURE_OPENAI_ENDPOINT else 'N√£o configurado'}
    **Status:** {status}
    **Vers√£o API:** {API_VERSION}
    **Limite:** 50K tokens/min
    """)
    
    st.divider()

    
#Area Principal
chat_container = st.container()

with chat_container:
    for message in st.session_state.messages:
        if message["role"] != "system":
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

# Input do usu√°rio
if prompt := st.chat_input("üí¨ Digite sua mensagem..."):
    # Adiciona mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Gera resposta
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        with st.spinner("ü§î Pensando..."):
            try:
                client = get_openai_client()
                
                if client is None:
                    st.error("‚ùå Cliente n√£o inicializado. Verifique suas credenciais.")
                    st.stop()
                
                # Prepara mensagens
                messages_for_api = st.session_state.messages.copy()
                
                # Faz a chamada √† API com STREAMING
                response = client.chat.completions.create(
                    model=MODEL_DEPLOYMENT,
                    messages=messages_for_api,
                    temperature=temperatura,
                    max_tokens=max_tokens,
                    top_p=top_p,
                    stream=True
                )
                
                # Processa streaming
                full_response = ""
                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        message_placeholder.markdown(full_response + "‚ñå")
                
                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                error_message = str(e)
                st.error(f"‚ùå Erro na gera√ß√£o da resposta")
                
                # Tratamento espec√≠fico de erros
                if "401" in error_message:
                    st.warning("üîë **Erro de autentica√ß√£o**: Verifique se sua chave de API est√° correta no arquivo .env")
                elif "404" in error_message:
                    st.warning(f"üîç **Modelo n√£o encontrado**: Verifique se o nome '{MODEL_DEPLOYMENT}' est√° correto")
                elif "429" in error_message:
                    st.warning("‚è≥ **Limite de taxa excedido**: Aguarde um momento (limite: 50K tokens/min)")
                elif "Connection" in error_message:
                    st.warning(f"üåê **Erro de conex√£o**: Verifique se o endpoint '{AZURE_OPENAI_ENDPOINT}' est√° acess√≠vel")
                else:
                    st.info(f"Detalhes: {error_message[:200]}...")

# Rodap√©
st.divider()
col1, col2, col3 = st.columns(3)
with col1:
    st.caption(f"üîí Autentica√ß√£o: **Chave de API**")
with col2:
    st.caption(f"ü§ñ Modelo: **{MODEL_DEPLOYMENT}**")
with col3:
    st.caption(f"üìä Limite: **50K tokens/min**")
```

Para executar utilize o comando:

```bash
streamlit run app.py
```

N√£o esque√ßa que o ambiente virtual deve estar ativo e ao executar deve-se estar na pasta do arquivo `app.py`

Caso n√£o tenha realizado a configura√ß√£o do ambiente veja os passos para realizar:

```text
1¬™ - Configura√ß√£o do Ambiente Virtual
	* python -m venv .venv 

2¬∫ - instala√ß√£o da Politica
	* Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

3¬∫ - Ativi√ß√£o do Ambiente Virtual
	* .venv\Scripts\Activate.ps1 

4¬∫ - Instala√ß√£o do arquivo requerements.txt
	*  pip install -r requirements.txt

5¬∫ - Executar o arquivo principal
	* streamlit run app.py
```