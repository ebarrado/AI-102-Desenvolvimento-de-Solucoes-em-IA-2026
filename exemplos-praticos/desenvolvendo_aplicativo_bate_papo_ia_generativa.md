# Desenvolvendo um aplicativo de bate-papo com IA generativa

>ExercÃ­cio adaptado - Microsoft Learn utilizando SDK Python do Microsoft Foundry

# Criar Grupo de Recursos - Portal Azure

1. Abra o [Portal do Azure](https://portal.azure.com/)
2. Crie um grupo de recurso com o nome: `rg-sobrenome-ano`

![alt text](/imagens/resource_group.png)

> Importante: o grupo de recurso deve estar na regiÃ£o `eastus2`, seguindo a regra da polÃ­tica `Allowed resource deployment regions`

* Para encontrar as regiÃµes que poderÃ¡ provisionar os recursos Azure, acesse: **Portal Azure - PolÃ­ticas - CriaÃ§Ã£o - AtribuiÃ§Ãµes - Allowed resource deployment regions**.

![alt text](/imagens/politicas_regions_azure.png) 

![alt text](/imagens/allowed_resource.png)

> Veja na imagem que na referida conta sÃ³ podemos provisionar recursos nas regiÃµes `["eastus","brazilsouth","northcentralus","mexicocentral","eastus2"]`
> Para serviÃ§os de AI generativa iremos utilizar sempre `eastus2`

## Por que  `eastus2` para IA Generativa?

A regiÃ£o **eastus2** Ã© recomendada porque:

### 1ï¸âƒ£ Maior disponibilidade de modelos
Muitos modelos de IA generativa (como GPT-4o e modelos de raciocÃ­nio) sÃ£o disponibilizados primeiro ou exclusivamente em regiÃµes especÃ­ficas.  
A eastus2 geralmente possui melhor suporte a modelos mais recentes.

### 2ï¸âƒ£ Melhor compatibilidade com serviÃ§os de IA
Alguns recursos do Azure AI Foundry e Azure OpenAI possuem dependÃªncia regional.  
Utilizar eastus2 reduz a chance de erro de cota ou indisponibilidade de modelo.

### 3ï¸âƒ£ Estabilidade e suporte global
A regiÃ£o eastus2 Ã© uma das regiÃµes principais (core regions) do Azure, com:
- Alta disponibilidade
- Melhor suporte a atualizaÃ§Ãµes
- Maior capacidade de escalabilidade

### 4ï¸âƒ£ Evita problemas de cota
Determinadas regiÃµes podem nÃ£o ter cota liberada para modelos especÃ­ficos.  
Padronizar eastus2 reduz falhas durante a implantaÃ§Ã£o.


# ðŸŒ Exemplos de regiÃµes com suporte a IA generativa no Azure
Estas regiÃµes geralmente suportam serviÃ§os de IA como Azure OpenAI ou Azure AI Foundry (incluindo modelos de linguagem e visÃ£o), sujeitas Ã  disponibilidade de modelo e cota:

### ðŸŒŽ AmÃ©ricas

* East US 2 (forte suporte a modelos mais recentes)
* Central US
* South Central US
* West US 2
* West US 3
* Canada Central

### ðŸ‡§ðŸ‡· AmÃ©rica do Sul

* Brazil South

### ðŸ‡ªðŸ‡º Europa

* France Central
* North Europe
* West Europe
* (Outras podem ter suporte parcial conforme serviÃ§o)

### ðŸŒ Ãsiaâ€“PacÃ­fico

* Australia East
* Japan East
* Korea Central
* Southeast Asia

### ðŸŒ Outros

* UK South

# Implantar um modelo - projeto Microsoft Foundry

1. Abra o [portal do Foundry](https://ai.azure.com)
2. Em explorar modelos e funcionalidade - Ir para o catÃ¡logo de modelos completo. Pesquise por `gpt-4o`

![alt text](/imagens/catalogo_modelos.png)

3. ApÃ³s selecionar o modelo, clique no botÃ£o **Usar esse modelo**

![alt text](/imagens/gpt-4o.png)

4. Ao solicitado para selecionar um projeto, clique em criar projeto e insira um nome vÃ¡lido para o projeto
    * Exemplo: `chat-ai-exemplo-aula`

![alt text](/imagens/project_name.png)

> Para um projeto Foundry no Azure AI, escolha nomes descritivos, Ãºnicos e seguindo convenÃ§Ãµes Azure (letras minÃºsculas, hÃ­fens, sem espaÃ§os). Aqui vÃ£o sugestÃµes baseadas no contexto do seu app de chat IA:



| PropÃ³sito        | Nome Sugerido      | Formato              |
| ---------------- | ------------------ | -------------------- |
| Chat IA Pessoal  | chat-ia-marilia    | Local + funÃ§Ã£o       |
| App Web Demo     | chat-ai-foundry    | Produto + plataforma |
| ProtÃ³tipo GPT-4o | gpt4o-chat-app     | Modelo + app         |
| Teste Foundry    | foundry-chat-br    | Plataforma + regiÃ£o  |
| IA Generativa    | ai-chat-marilia-sp | FunÃ§Ã£o + localizaÃ§Ã£o |

>Importante: Veja se a regiÃ£o estÃ¡ em `East US 2`, caso nÃ£o esteja altere. Observe o `Grupo de Recursos` e selecione o grupo de recurso criado na `Etapa 1`
* ApÃ³s selecionar corretamente a assinatura Â´Azure for Students, o `Grupo de Recursos`e a `RegiÃ£o East US2`, clique em **Criar e Continuar**

![alt text](/imagens/criando_projeto.png)


5. Na tela de implantaÃ§Ã£o do modelo, o nome deve ser um indicador Ãºnico que Ã© definido para referÃªnciar o modelo no SDK/CÃ³digo

### Regras de NomeaÃ§Ã£o
* MinÃºsculas, hÃ­fens, 1-32 chars
* Sem espaÃ§os ou caracteres especiais
* Ãšnico no projeto
#### Exemplos:â€‹
| Nome        | Quando Usar        | Vantagem            |
| ----------- | ------------------ | ------------------- |
| gpt-4o-chat | Apps de chat       | Descritivo          |
| chat-model  | Projetos genÃ©ricos | Simples             |
| gpt4o-prod  | ProduÃ§Ã£o           | Identifica ambiente |
| modelo-chat | PortuguÃªs          | Linguagem local     |

* Utilizaremos para o exemplo de modelo: `modelo-chat-sobrenome`

Os tipos de implantaÃ§Ã£o no Azure AI Foundry definem como seu modelo gpt-4o Ã© hospedado, roteado e cobrado, otimizando para latÃªncia, cota e conformidade.
â€‹

## Tipos de ImplantaÃ§Ã£o DisponÃ­veis

| Tipo               | ExplicaÃ§Ã£o                                                                 | Quando Usar                             | CobranÃ§a          |
| ------------------ | -------------------------------------------------------------------------- | --------------------------------------- | ----------------- |
| Global Standard    | Roteia globalmente para melhor data center disponÃ­vel. Maior cota inicial. | âœ… Seu chat app - mÃ¡xima disponibilidade | Por token         |
| DataZone Standard  | Limita processamento a zona de dados (US/EU). Conformidade GDPR.           | Apps regulados                          | Por token         |
| Standard           | Hospedagem regional bÃ¡sica. LatÃªncia previsÃ­vel.                           | Testes locais                           | Por chamada       |
| ProvisionedManaged | Reserva capacidade fixa (PTUs). Alta taxa de transferÃªncia garantida.      | ProduÃ§Ã£o pesada                         | Por PTU/hora      |
| GlobalBatch        | Processamento em lote assÃ­ncrono global.                                   | AnÃ¡lise massiva                         | Por token (batch) |
| DataZoneBatch      | Lote restrito a zona de dados.                                             | Batch regulado                          | Por token (batch) |

A cobranÃ§a `por token`significa pagar pelo uso real do modelo de IA, medido em pequenas unidades de texto chamanhdas tokens.

## Token

```text
1 token â‰ˆ 4 caracteres (texto inglÃªs)
"OlÃ¡ mundo" = ~3 tokens
"Explique IA generativa" = ~6 tokens
```

#### Pagamento por Entrada + SaÃ­da

```text
Pergunta (input): 100 tokens
Resposta (output): 200 tokens  
TOTAL: 300 tokens Ã— preÃ§o/1.000 tokens
```
### Exemplo PrÃ¡tico (gpt-4o Global Standard)

```text
PreÃ§o variÃ¡vel: R$0,01 por 1.000 tokens entrada
                     R$0,03 por 1.000 tokens saÃ­da

Chat tÃ­pico:
- Sua pergunta: 50 tokens Ã— R$0,01/1k = R$0,0005
- Resposta IA: 150 tokens Ã— R$0,03/1k = R$0,0045  
**TOTAL: ~R$0,005 por conversa**
```
## DiferenÃ§a vs Outros Modelos
| Modelo      | CobranÃ§a     | Exemplo           |
| ----------- | ------------ | ----------------- |
| Por Token   | Uso real     | 10 chats = R$0,05 |
| PTU/Hora    | Reserva fixa | R$50/mÃªs (fixo)   |
| Por Chamada | Cada request | R$0,10/chat       |

![alt text](/imagens/config_implantacao.png)

No nosso caso verifique se a regiÃ£o `East US 2`estÃ¡ selecionada, se nÃ£o tiver clique em Personalizar e altere para `East US 2`

> Veja que aparece a opÃ§Ã£o `Limite de Taxa de Tokens de cota disponÃ­vel para sua implantaÃ§Ã£o`e pode chegar atÃ© 50K. Isso significa que sÃ£o `50K por minuto`, que sua implantaÃ§Ã£o gpt-4o pode processar 50.000 tokens a cada minuto antes de atingir o limite de cota.

### Representa:

```text
50K TPM = 50.000 tokens/minuto
1 chat tÃ­pico = ~200 tokens (pergunta + resposta)
âœ… 250 chats por minuto
âœ… 15.000 chats por hora
âœ… 360.000 chats por dia
```

Para um App Streamlit:

```
âœ… Perfeito para:
- 100 usuÃ¡rios simultÃ¢neos
- 1.000 usuÃ¡rios/dia
- App pÃºblico pequeno/mÃ©dio
```
## Exemplo:

```text
["Qual", " Ã©", " a", " capital", " do", " Brasil", "?"]
= 7 tokens
Resposta tÃ­pica: "A capital do Brasil Ã© BrasÃ­lia."
âœ… Output: 8 tokens

TOTAL por chat: 15 tokens

50.000 tokens/min Ã· 15 tokens/chat
= **3.333 chats por minuto**
âœ… Ampla capacidade para seu app
```

6. ApÃ³s clicar em `Impantar`, aguarde. 
> Se aparecer algum tipo de erro por causa de cota - altere o modelo, para outro modelo de `conclusÃ£o de chat` e tente novamente - pode ser a capacidade limitada para nossas contas de estudante.

* Veja a tela que abriu na guia Geral

![alt text](/imagens/modelo_chat_barrado.png)

# Criando App Web de Chat com IA Generativa

Nosso projeto utilizarÃ¡:
* Streamlit
* Azure AI Projects SDK
* VS Code

1. ApÃ³s implantar o modelo no Microsoft Foundry
2. Instale e configure o VS Code com extensÃµes Python e Azure
3. Acesse Azure no VS Code e realize o Login com a conta da Assinatura Azure

    * Abra o Terminal
    * Digite: `az login`
    * Autentique as credenciais
    * Selecione a conta com a qual deseja iniciar sessÃ£o.
![alt text](/imagens/login_tenant.png)

![alt text](/imagens/conta_azure.png)

4. Liste as assinaturas da sua conta com o comando: `az account list --output table`
5. Copie a Subscription ID ativa na sua conta e adicione ao comando: 
    * `az account set --subscription "nome-ou-id"`

6. Adicione a conta a extensÃ£o do Azure no VS Code

![alt text](/imagens/conta_azure_vs.png)

# Estrutura do Projeto

```text
chat-ai-app/
â”œâ”€â”€ app.py              # App Streamlit
â”œâ”€â”€ .env               # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements.txt   # DependÃªncias
â””â”€â”€ README.md
```
1. Crie um novo projeto no VS Code como o nome: `chat-ai-app`
2. Crie um arquivo `requirements.txt`
    * Adicione as versÃµes:

```text
streamlit==1.38.0
azure-identity==1.19.0
azure-ai-projects==1.0.0b1
openai==1.51.2
python-dotenv==1.0.1
```

| Pacote          | VersÃ£o        | FunÃ§Ã£o no Seu App       |
| -------------- | ------------- | ---------------- |
| streamlit==1.38.0          | Interface web | Cria o chat UI com st.chat_input(), st.chat_message() |
| azure-identity==1.19.0     | AutenticaÃ§Ã£o  | DefaultAzureCredential() para login Azure AD          |
| azure-ai-projects==1.0.0b1 | Core IA       | AIProjectClient(endpoint=...) conecta ao Foundry      |
| openai==1.51.2             | InferÃªncia    | client.chat.completions.create(model="gpt-4o")        |
| python-dotenv==1.0.1       | Config        | Carrega PROJECT_ENDPOINT e MODEL_DEPLOYMENT do .env   |

3. Crie um arquivo `.env`
```text
PROJECT_ENDPOINT=https://seu-projeto.projects.ai.azure.com
MODEL_DEPLOYMENT=gpt-4o
```
* Configure com os valores do projeto criado no Microsoft Foundry

4. Crie um arquivo `app.py`
5. Execute no VS Code
    * Abra o Terminal no VS Code
    * Crie um ambiente virtual: `python -m venv .venv`
    * Ative: `.venv\Scripts\activate` (Windows) ou source `.venv/bin/activate` (Linux/Mac)
    * Instale dependÃªncias: `pip install -r requirements.txt`
    * Execute: `streamlit run app.py`

# ReferÃªncia

* [Create a generative AI chat app](https://microsoftlearning.github.io/mslearn-ai-studio/Instructions/02a-AI-foundry-sdk.html)
* [RegiÃµes com suporte a idioma](https://learn.microsoft.com/pt-br/azure/ai-services/language-service/concepts/regional-support?utm_source=chatgpt.com)
* [Azure OpenAI in Microsoft Foundry Models quotas and limits] (https://learn.microsoft.com/en-us/azure/ai-foundry/openai/quotas-limits?view=foundry-classic&tabs=REST)